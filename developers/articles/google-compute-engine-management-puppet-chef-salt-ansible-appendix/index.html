{% comment %}
This document is sourced from GitHub. 
Do not change this file in a CL!
Instead, edit me at: 
https://github.com/GoogleCloudPlatformSite/GoogleCloudPlatformSite.github.io/edit/master/developers/articles/google-compute-engine-management-puppet-chef-salt-ansible-appendix.html
{% endcomment %}
<!DOCTYPE html>
<html devsite>
<head>
    <title>Compute Engine Management with Puppet, Chef, Salt, and Ansible - Appendix </title>
    
      <meta name="description" content="Google Cloud Platform lets you build and host applications and websites, store data, and analyze data on Google's scalable infrastructure.">
    
    <meta name="hide_page_heading" value="true" />
    <meta name="full_width" value="true" />
</head>
<body>

<div id="maia-main" class="cp-article">
  <div class="maia-cols">
    <div class="maia-col-9">

      <div>
        <div style="float:right"><div class="g-plusone"></div></div>
        <h1 class="title">Compute Engine Management with Puppet, Chef, Salt, and Ansible - Appendix</h1>
      </div>

      

<style>
table th {
  color: #FFF;
  background-color: #6199df;
  text-align: left;
}

table td {
  text-align: left;
}


.c64 {
  vertical-align: baseline;
  font-size: 10pt;
  font-style: normal;
  font-family: "Open Sans";
  text-decoration: none;
  font-weight: 400;
}

.c80 {
  vertical-align: baseline;
  font-size: 10pt;
  font-style: normal;
  font-family: "Open Sans";
  text-decoration: none;
}

.c2 {
  line-height: 1.0;
  padding-top: 0;
  height: 10pt;
  direction: ltr;
}

.c6 {
  padding-left: 0;
  line-height: 1.1079545454545454;
  padding-top: 0;
  margin-left: 36pt;
}

.c13 {
  padding-left: 0;
  margin-left: 36pt;
  padding-bottom: 0;
}

.c7 {
  padding-top: 10pt;
  widows: 2;
  orphans: 2;
}

.c1 {
  color: #222;
  font-size: 9pt;
  font-family: "Courier New";
}

.c40 {
  margin-right: auto;
  border-collapse: collapse;
}

.c12 {
  line-height: 1.0;
  padding-top: 0;
  padding-bottom: 0;
}

.c17 {
  line-height: 1.0;
  padding-top: 0;
  margin-left: 36pt;
}

.c23 {
  padding-left: 0;
  margin-left: 36pt;
}

.c14 {
  padding-top: 11pt;
  padding-bottom: 2pt;
}

.c16 {
  color: #900;
  font-weight: 700;
}

.c5 {
  color: inherit;
  text-decoration: inherit;
}

.c25 {
  line-height: 1.1079545454545454;
  height: 10pt;
}

.c8 {
  font-size: 9pt;
  font-family: "Courier New";
}

.c9 {
  padding-top: 10pt;
  padding-bottom: 0;
}

.c74 {
  height: 1px;
  width: 33%;
}

.c62 {
  padding-top: 12pt;
  padding-bottom: 2pt;
}

.c10 {
  margin: 0;
  padding: 0;
}

.c32 {
  padding-left: 0;
  margin-left: 72pt;
}

.c76 {
  margin-right: auto;
  border-collapse: collapse;
}

.c47 {
  height: 10pt;
  text-align: right;
}

.c22 {
  widows: 2;
  orphans: 2;
}

.c36 {
  color: #666;
  font-size: 11pt;
}

.c20 {
  height: 10pt;
  margin-left: 36pt;
}

.c72 {
  padding-top: 14pt;
  padding-bottom: 4pt;
}

.c3 {
  color: #15c;
  text-decoration: underline;
}

.c78 {
  font-size: 11pt;
  font-family: Arial;
}

.c18 {
  line-height: 1.0;
  padding-top: 0;
}

.c75 {
  max-width: 504pt;
  padding: 72pt 54pt;
}

.c70 {
  text-align: right;
}

.c29 {
  color: #222;
}

.c81 {
  color: #1c4587;
}

.c52 {
  padding-bottom: 0;
}

.c31 {
  line-height: 1.1079545454545454;
}

.c26 {
  color: #15c;
}

.c51 {
  background-color: #fff;
}

.c63 {
  color: #00f;
}

.c28 {
  text-align: left;
}

.c69 {
  color: #61c;
}

.c50 {
  height: 10pt;
}

.c37 {
  text-indent: 36pt;
}

.c33 {
  margin-left: 36pt;
}

.c42 {
  color: #900;
}

.c65 {
  text-align: center;
}

.c11 {
  font-family: "Courier New";
}

.c67 {
  page-break-after: avoid;
}

.c44 {
  /* background-color: #333; */
}

.c68 {
  color: #666;
}

.c79 {
  text-decoration: underline;
}

.c30 {
  color: #fff;
}

.c48 {
  color: #38761d;
}

.c15 {
  height: 0;
}

.c21 {
  padding-top: 0;
}

.c19 {
  font-weight: 700;
}

.c4 {
  direction: ltr;
}

.c41 {
  height: 14pt;
}

.c56 {
  color: #3c78d8;
}

.c0 {
  font-style: italic;
}

.c24 {
  text-align: center;
  margin-left: 50px;
}

</style>

<div class="cp-article-tutorial">

  <p class="c4"><span>The following sections provide step-by-step instructions to help
  you get started with the cloud management tools discussed in
  <a target="_blank" href="google-compute-engine-management-puppet-chef-salt-ansible">this article</a>.</span>
  <span>The listed commands are valid as of the time of this writing
  (</span><span>February</span> <span>2014).</span> <span>Please check the websites for
  Google Compute Engine and the individual tools for the most up-to-date
  information.</span></p>

  <h3 class="c4"><a name="h.dwyj6x3zt2um" ></a><span>Appendix A:
  Resource management with gcutil</span></h3>

  <p class="c4"><span>Google provides a programmatic API and a command line tool to
  manage cloud resources. You can use the</span> <span class="c3"><a class="c5" target="_blank" href=
  "/compute/docs/reference/latest/">Compute Engine
  API</a></span><span>&nbsp;and</span> <span class="c3 c11"><a class="c5" target="_blank" href=
  "/compute/docs/gcutil/">gcutil</a></span><span>&nbsp;to
  manage all Compute Engine resources, including but not limited to:</span></p>

  <ul class="c10 lst-kix_9j4o6iq4x9t3-0 start">
    <li class="c23 c4"><span>Virtual machine instances and disks</span></li>

    <li class="c23 c4"><span>Networks and firewalls</span></li>

    <li class="c23 c4"><span>Load balancers</span></li>
  </ul>

  <p class="c22 c21 c4"><span class="c29">The following core</span> <span class=
  "c29 c11">gcutil</span><span class="c29">&nbsp;commands are provided for managing
  Compute Engine resources:</span></p>

  <table cellpadding="0" cellspacing="0" class="c40">
    <tbody>
      <tr class="c15">
        <th class="c34 c44">
          <p class="c22 c18 c4"><span class="c30 c19">Resource</span></p>
        </th>

        <th class="c59 c44">
          <p class="c22 c18 c4"><span class="c30 c19">Add</span></p>
        </th>

        <th class="c60 c44">
          <p class="c22 c18 c4"><span class="c30 c19">Delete</span></p>
        </th>

        <th class="c49 c44">
          <p class="c22 c18 c4"><span class="c30 c19">Get</span></p>
        </th>

        <th class="c46 c44">
          <p class="c22 c18 c4"><span class="c30 c19">List</span></p>
        </th>
      </tr>

      <tr class="c15">
        <td class="c34">
          <p class="c18 c4"><span>Instances</span></p>
        </td>

        <td class="c59">
          <p class="c22 c21 c4"><span class="c1">addinstance</span></p>
        </td>

        <td class="c60">
          <p class="c22 c21 c4"><span class="c1">deleteinstance</span></p>
        </td>

        <td class="c49">
          <p class="c22 c21 c4"><span class="c1">getinstance</span></p>
        </td>

        <td class="c46">
          <p class="c22 c21 c4"><span class="c1">listinstances</span></p>
        </td>
      </tr>

      <tr class="c15">
        <td class="c34">
          <p class="c18 c4"><span>Disks</span></p>
        </td>

        <td class="c59">
          <p class="c22 c21 c4"><span class="c1">adddisk</span></p>
        </td>

        <td class="c60">
          <p class="c22 c21 c4"><span class="c1">deletedisk</span></p>
        </td>

        <td class="c49">
          <p class="c22 c21 c4"><span class="c1">getdisk</span></p>
        </td>

        <td class="c46">
          <p class="c22 c21 c4"><span class="c1">listdisks</span></p>
        </td>
      </tr>

      <tr class="c15">
        <td class="c34">
          <p class="c18 c4"><span>Networks</span></p>
        </td>

        <td class="c59">
          <p class="c22 c21 c4"><span class="c1">addnetwork</span></p>
        </td>

        <td class="c60">
          <p class="c22 c21 c4"><span class="c1">deletenetwork</span></p>
        </td>

        <td class="c49">
          <p class="c22 c21 c4"><span class="c1">getnetwork</span></p>
        </td>

        <td class="c46">
          <p class="c22 c21 c4"><span class="c1">listnetworks</span></p>
        </td>
      </tr>

      <tr class="c15">
        <td class="c34">
          <p class="c18 c4"><span>Firewalls</span></p>
        </td>

        <td class="c59">
          <p class="c22 c21 c4"><span class="c1">addfirewall</span></p>
        </td>

        <td class="c60">
          <p class="c21 c4 c22"><span class="c1">deletefirewall</span></p>
        </td>

        <td class="c49">
          <p class="c22 c21 c4"><span class="c1">getfirewall</span></p>
        </td>

        <td class="c46">
          <p class="c22 c21 c4"><span class="c1">listfirewalls</span></p>
        </td>
      </tr>

      <tr class="c15">
        <td class="c34">
          <p class="c22 c18 c4"><span>Load Balancing</span></p>
        </td>

        <td class="c59">
          <p class="c18 c4"><span class="c8">addhttphealthcheck<br />
          addtargetpool<br />
          addforwardingrule</span></p>
        </td>

        <td class="c60">
          <p class="c18 c4"><span class="c8">deletehttphealthcheck<br />
          deletetargetpool<br />
          deleteforwardingrule</span></p>
        </td>

        <td class="c49">
          <p class="c18 c4"><span class="c8">gethttphealthcheck<br />
          gettargetpool<br />
          getforwardingrule</span></p>
        </td>

        <td class="c46">
          <p class="c18 c4"><span class="c8">listhttphealthchecks<br />
          listtargetpools<br />
          listforwardingrules</span></p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="c22 c52 c50 c21 c4"></p>

  <p class="c22  c21 c4"><span class="c29 c11">gcutil</span><span class=
  "c29">&nbsp;will always provide commands closely aligned to Compute Engine features and
  the API.</span></p>

  <h4 class="c22 c21 c4"><a name="h.4tm0wwd0hnmi" ></a><span>Instance
  launch and software install</span></h4>

  <p class="c22  c21 c4"><span class="c29">To launch an instance and specify a startup
  script:</span></p>

  <p class="c17 c4"><span class="c11 c19"># Create a persistent disk from a base
  image.</span></p>

  <p class="c17 c4"><span class="c11">gcutil adddisk</span> <span class=
  "c11 c0">my-boot-disk</span><span class="c11">&nbsp;\<br />
  &nbsp; --source_image=debian-7 \<br />
  &nbsp; --zone=us-central1-a<br /><br /></span></p>

  <p class="c17 c4"><span class="c11 c19"># Create a Compute Engine instance, booting
  from the persistent disk.<br />
  # Specify a startup script to be run (my-startup-script.sh).</span><br /><br/><span class=
  "c11">gcutil addinstance</span> <span class="c11 c0">my-instance</span><span class=
  "c11">&nbsp;\<br />
  &nbsp; --machine_type=n1-standard-2 \<br />
  &nbsp; --zone=us-central1-a \<br />
  &nbsp; --disk=</span><span class="c11 c0">my-boot-disk</span><span class="c11">,boot
    \<br />
  &nbsp; --metadata_from_file=startup-script:my-startup-script.sh</span><br/><br/></p>

  <p class="c4"><span class="c11">gcutil adddisk</span><span>&nbsp;and</span>
  <span class="c11">gcutil addinstance</span><span>&nbsp;can be used to create multiple
  disks and instances in parallel. &nbsp;This can significantly speed up cluster startup
  time when creating multiple identically configured instances.</span></p>

  <h4 class="c4"><a name="h.77mnab6vxjzf" ></a><span>Software
  upgrade</span></h4>

  <p class="c4"><span>To perform software upgrades using</span> <span class=
  "c11">gcutil</span><span>, you can do one of the following:</span></p>

  <ul class="c10 lst-kix_z08zk4osysp9-0 start">
    <li class="c23 c4"><span>Update startup scripts and restart your
    instances.</span></li>

    <li class="c23 c4"><span>Create upgrade scripts, push them to your instances, and run
    them.</span></li>
  </ul>

  <p class=" c4"><span>To push a file to a specific instance with</span> <span class=
  "c11">gcutil</span><span>, use the</span> <span class=
  "c11">push</span><span>&nbsp;command:</span></p>

  <p class="c22 c33 c21 c4"><span class="c11">gcutil push</span> <span class=
  "c11 c0">my-instance local_file remote_directory</span></p>

  <p class="c7 c4"><span>To run a file on an instance with</span> <span class=
  "c11">gcutil</span><span>, use the</span> <span class=
  "c11">ssh</span><span>&nbsp;command:</span></p>

  <p class="c7 c33 c4"><span class="c11">gcutil ssh</span> <span class=
  "c11 c0">my-instance /remote_directory/</span><span class=
  "c11 c0">remote_file</span></p>

  <h3 class="c4 c72"><a name="h.cyt7suu7ylub" ></a><span>Appendix B:
  Getting started with Puppet on Compute Engine</span></h3>

  <h4 class="c4"><a name="h.ws3kblm6kubs" id=
  "h.ws3kblm6kubs"></a><span>Standalone</span></h4>

  <ol class="c10 lst-kix_4sbpovohyzzc-0 start" start="1">
    <li class="c23  c4"><span class="c3"><a class="c5" target="_blank" href=
    "http://docs.puppetlabs.com/guides/installation.html">Install Puppet on your
    workstation</a></span><span>.</span></li>

    <li class="c23 c4"><span>Install the</span> <span class="c3"><a class="c5" target="_blank" href=
    "https://forge.puppetlabs.com/puppetlabs/gce_compute">gce_compute</a></span><span>&nbsp;module
    on your workstation.<br />
    </span><p><span class="c11">puppet module install
    puppetlabs-gce_compute<br /></span></p></li>

    <li class="c23 c4"><span class="c3"><a class="c5" target="_blank" href=
    "/compute/docs/gcutil/#install">Install and configure
    gcutil</a></span><span>&nbsp;on your workstation.<br /></span></li>

    <li class="c23 c4"><span>Set up a</span> <span class=
    "c11">device.conf</span><span>&nbsp;file</span><span>. This typically goes into
    the</span> <span class="c11">$HOME/.puppet/</span><span>directory.</span></li>
  </ol>

  <table cellpadding="0" cellspacing="0" class="c24">
    <tbody>
      <tr>
        <td class="c77">
          <p class="c12 c4"><span class="c11">[</span><span class=
          "c11 c0">my_project</span><span class="c11">]<br />
          &nbsp;type gce<br />
          &nbsp;url [/dev/null]:</span><span class="c11 c0">gce_project_id</span></p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="c33 c4"><span>Where:</span></p>

  <ul class="c10 lst-kix_vmla6jtafrv2-0 start">
    <li class="c32 c4"><span class=
    "c0">my_project</span><span>&nbsp;is any name you choose.</span></li>

    <li class="c32 c4"><span class="c0">gce_project_id</span><span>&nbsp;is the Project
    ID of your Compute Engine project.<br /></span></li>
  </ul>
  <p></p>
  <ol class="c10 lst-kix_4sbpovohyzzc-0" start="5">
    <li class="c23 c4"><span>Create a manifest file for creating Compute Engine
    resources. Call it</span> <span class=
    "c11">puppet-www.pp</span><span>.</span><span><br /></span></li>
  </ol><a href="#" name="8832b3a20616db9c31493813d967e81e93e9aaaa"></a><a href="#" name=
  "6"></a>

  <table cellpadding="0" cellspacing="0" class="c24">
    <tbody>
      <tr>
        <td class="c66">
          <p class="c12 c4"><span class="c8">$zone = 'us-central1-a'</span></p>


          <p class="c12 c4"><span class="c8">gce_firewall { 'puppet-www-http':<br />
          &nbsp;ensure &nbsp; &nbsp; &nbsp;=&gt; present,<br />
          &nbsp;network &nbsp; &nbsp; =&gt; 'default',<br />
          &nbsp;description =&gt; 'allows incoming HTTP connections',<br />
          &nbsp;allowed &nbsp; &nbsp; =&gt; 'tcp:80',<br />
          }<br /></span></p>

          <p class="c12 c4"><span class="c8">gce_disk { 'puppet-www-boot':<br />
          &nbsp; ensure &nbsp; &nbsp; &nbsp; =&gt; present,<br />
          &nbsp; source_image =&gt; 'debian-7',<br />
          &nbsp; size_gb &nbsp; &nbsp; &nbsp;=&gt; '10',<br />
          &nbsp; zone &nbsp; &nbsp; &nbsp; &nbsp; =&gt; "$zone",<br />
          }</span></p>

          <p class="c12 c4"><span class="c8">gce_instance { 'puppet-www':<br />
          &nbsp; ensure &nbsp; &nbsp; &nbsp; =&gt; present,<br />
          &nbsp; description &nbsp;=&gt; 'Basic web server',<br />
          &nbsp; machine_type =&gt; n1-standard-1,<br />
          &nbsp; disk &nbsp; &nbsp; &nbsp; &nbsp; =&gt; 'puppet-www-boot,boot',<br />
          &nbsp; zone &nbsp; &nbsp; &nbsp; &nbsp; =&gt; "$zone",<br />
          &nbsp; network &nbsp; &nbsp; &nbsp;=&gt; 'default',<br />
          <br />
          &nbsp; require &nbsp; =&gt; Gce_disk['puppet-www-boot'],<br /></span></p>

          <p class="c12 c4"><span class="c8">&nbsp; puppet_master =&gt; "",<br />

          &nbsp; manifest &nbsp; &nbsp; =&gt; '<br />
          &nbsp; &nbsp; class apache ($version = "latest") {<br />
          &nbsp; &nbsp; &nbsp; package {"apache2":<br />
          &nbsp; &nbsp; &nbsp; &nbsp; ensure =&gt; $version,<br />
          &nbsp; &nbsp; &nbsp; }<br />
          &nbsp; &nbsp; &nbsp; file {"/var/www/":<br />
          &nbsp; &nbsp; &nbsp; &nbsp; ensure &nbsp;=&gt; present,<br />
          &nbsp; &nbsp; &nbsp; &nbsp; content =&gt; "&lt;html&gt;\n&lt;body&gt;\n\t&lt;h2&gt;Hi, this is $hostname
          ($gce_external_ip).&lt;/h2&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n",<br />
          &nbsp; &nbsp; &nbsp; &nbsp; require =&gt; Package["apache2"],<br />
          &nbsp; &nbsp; &nbsp; }<br />
          &nbsp; &nbsp; &nbsp; service {"apache2":<br />
          &nbsp; &nbsp; &nbsp; &nbsp; ensure =&gt; running,<br />
          &nbsp; &nbsp; &nbsp; &nbsp; enable =&gt; true,<br />
          &nbsp; &nbsp; &nbsp; &nbsp; require =&gt; File["/var/www/"],<br />
          &nbsp; &nbsp; &nbsp; }<br />
          &nbsp; &nbsp; }<br />
          <br />
          &nbsp; &nbsp; include apache',<br />
          }</span></p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="c50 c21 c4"></p>

  <ol class="c10 lst-kix_4sbpovohyzzc-0" start="6">
    <li class="c23 c4"><span>Apply the manifest file.</span></li>
  </ol>

  <p class="c33 c4"><span class="c11">puppet apply --certname</span> <span class=
  "c11 c0">my_project</span><span class="c11">&nbsp;puppet-www.pp</span></p>

  <h4 class="c4"><a name="h.6l9pa8s0sl9y" id=
  "h.6l9pa8s0sl9y"></a><span>Master/Agent</span></h4>

  <p class="c4"><span>In Master/Agent mode, managing Compute Engine resources and
  managing the software running on the associated instances are separated. Software
  management is under the domain of the Puppet Master. Compute Engine instances can be
  managed on the master instance or from any other workstation running Puppet. The
  instructions below are for performing Compute Engine resource management from the
  master instance.</span></p>

  <ol class="c10 lst-kix_rx7tnn4qnqb6-0 start" start="1">
    <li class="c23 c4"><span>Create a Compute Engine instance for the Puppet Master. This
    can be done from the</span> <span class="c3"><a class="c5" target="_blank" href=
    "https://console.developers.google.com">Developers Console</a></span><span>&nbsp;or
    with</span> <span class="c11">gcutil addinstance</span><span>&nbsp;from a workstation
    (</span><span>or with Puppet and</span> <span class=
    "c11">gce_compute</span><span>)</span><span>.<br /></span></li>

    <li class="c23 c4"><span>Connect to the Puppet Master instance via</span>
    <span class="c11">gcutil ssh</span><span>.<br /></span></li>

    <li class="c23 c4"><span class="c3"><a class="c5" target="_blank" href=
    "http://docs.puppetlabs.com/guides/installation.html">Install the Puppet Master
    software</a></span><span>.</span></li>

    <li class="c4 c13"><span>(Optional) Configure the Puppet Master service for
    autosigning (see</span> <span class="c3"><a class="c5" href="#h.6bm5u5lfs9ny">Puppet
    certificate management</a></span><span>&nbsp;below).</span><span><br />
    </span><p><span class="c11">echo "*.$(hostname --domain)" | sudo tee
    /etc/puppet/autosign.conf</span></p></li>

    <li class="c23  c4"><span>Create a site manifest file to specify instance software
    and services (</span><span class=
    "c11">/etc/puppet/manifest/site.pp</span><span>).</span></li>
  </ol><a href="#" name="8ffa11b3cfb060a6fc9eef5cc587012685ffe871"></a><a href="#" name=
  "7"></a>

  <table cellpadding="0" cellspacing="0" class="c24">
    <tbody>
      <tr class="c15">
        <td class="c73">
          <p class="c18 c4"><span class="c8">class apache ($version = "latest")
          {<br />
          &nbsp; package {"apache2":<br />
          &nbsp; &nbsp; ensure =&gt; $version,<br />
          &nbsp; }<br />
          &nbsp; file {"/var/www/":<br />
          &nbsp; &nbsp; ensure &nbsp;=&gt; present,<br />
          &nbsp; &nbsp; content =&gt; "&lt;html&gt;\n&lt;body&gt;\n\t&lt;h2&gt;Hi, this is
          $hostname.&lt;/h2&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n",<br />
          &nbsp; &nbsp; require =&gt; Package["apache2"],<br />
          &nbsp; }<br />
          &nbsp; service {"apache2":<br />
          &nbsp; &nbsp; ensure =&gt; running,<br />
          &nbsp; &nbsp; enable =&gt; true,<br />
          &nbsp; &nbsp; require =&gt; File["/var/www/"],<br />
          &nbsp; }<br />
          }<br />

          node 'puppet-child-www' {<br />
          &nbsp; include apache<br />
          }</span></p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="c33 c21 c4"><span>The Puppet Master is now ready.</span></p>

  <ol class="c10 lst-kix_rx7tnn4qnqb6-0" start="6">
    <li class="c23 c4"><span>Install the</span> <span class="c3"><a class="c5" target="_blank" href=
    "https://forge.puppetlabs.com/puppetlabs/gce_compute">gce_compute</a></span><span>&nbsp;module.<br /></span>
    <br />
    <span class="c11">puppet module install puppetlabs-gce_compute</span><br />
    <br />

    </li>

    <li class="c23  c4"><span>Set up</span> <span class="c11">device.conf</span><span>.</span></li>
  </ol>

  <p class="c33 c21 c4"><span class="c11">PROJECT=$(/usr/share/google/get_metadata_value
  project-id)</span></p>

  <p class="c33 c21 c4"><span class="c11">cat &gt; ~/.puppet/device.conf &lt;&lt; EOF<br />
  [my_project]<br />
  &nbsp; type gce<br />
  &nbsp; url [/dev/null]:${PROJECT}<br />
  EOF</span></p>

  <ol class="c10 lst-kix_rx7tnn4qnqb6-0" start="8">
    <li class="c23  c4"><span>Create a manifest file for creating Compute Engine
    instances and associated resources (</span><span class=
    "c11">gce_www_up.pp</span><span>).</span></li>
  </ol><a href="#" name="b438a10710f16753c07f7cf265577004f8e9bbef" id=
  "b438a10710f16753c07f7cf265577004f8e9bbef"></a><a href="#" name="8"></a>

  <table cellpadding="0" cellspacing="0" class="c24">
    <tbody>
      <tr class="c15">
        <td class="c73">
          <p class="c18 c4"><span class="c8">$master = $fqdn<br />
          $zone = 'us-central1-a'<br />
          <br />
          gce_firewall { 'allow-http':<br />
          &nbsp; ensure &nbsp; &nbsp; &nbsp; =&gt; present,<br />
          &nbsp; description &nbsp;=&gt; 'Allow HTTP',<br />
          &nbsp; network &nbsp; &nbsp; &nbsp;=&gt; 'default',<br />
          &nbsp; allowed &nbsp; &nbsp; &nbsp;=&gt; 'tcp:80',<br />
          &nbsp; allowed_ip_sources =&gt; '0.0.0.0/0',<br />
          }<br />
          <br />
          gce_disk { 'puppet-child-www':<br />
          &nbsp; ensure &nbsp; &nbsp; &nbsp; =&gt; present,<br />
          &nbsp; description &nbsp;=&gt; 'Boot disk for puppet-child-www',<br />
          &nbsp; size_gb &nbsp; &nbsp; &nbsp;=&gt; 10,<br />
          &nbsp; zone &nbsp; &nbsp; &nbsp; &nbsp; =&gt; "$zone",<br />
          &nbsp; source_image =&gt; 'debian-7',<br />
          }<br />
          <br />
          gce_instance { 'puppet-child-www':<br />
          &nbsp; ensure &nbsp; &nbsp; &nbsp; =&gt; present,<br />
          &nbsp; description &nbsp;=&gt; 'Basic web node',<br />
          &nbsp; machine_type =&gt; 'n1-standard-1',<br />
          &nbsp; zone &nbsp; &nbsp; &nbsp; &nbsp; =&gt; "$zone",<br />
          &nbsp; disk &nbsp; &nbsp; &nbsp; &nbsp; =&gt; 'puppet-child-www,boot',<br />
          &nbsp; network &nbsp; &nbsp; &nbsp;=&gt; 'default',<br />
          <br />
          &nbsp; require &nbsp; &nbsp; &nbsp;=&gt; Gce_disk['puppet-child-www'],<br />
          <br />
          &nbsp; puppet_master &nbsp;=&gt; "$master",<br />
          &nbsp; puppet_service =&gt; present,<br />
          }</span></p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="c50 c21 c4"></p>

  <ol class="c10 lst-kix_rx7tnn4qnqb6-0" start="9">
    <li class="c23 c4"><span>Apply the</span> <span class=
    "c11">gce_www_up.pp</span><span>&nbsp;manifest file.</span></li>
  </ol>

  <p class="c33 c4"><span class="c11">puppet apply --certname=my_project
  gce_www_up.pp</span></p>

  <ol class="c10 lst-kix_rx7tnn4qnqb6-0" start="10">
    <li class="c23 c4"><span>If you did not configure autosigning, then, on the Master,
    monitor the certificate requests from the new agent nodes and sign them as they
    arrive.</span></li>
  </ol>

  <p class="c4 c33"><span class="c11">sudo puppet cert list<br />
  sudo puppet cert sign [agent-hostname]</span></p>

  <h5 class="c4 c14"><a name="h.6bm5u5lfs9ny" ></a><span>Puppet
  certificate management</span></h5>

  <p class="c4"><span>Before an agent can receive its resource catalog from the master,
  the agent's SSL certificate must be accepted and signed by the</span>
  <span>master</span><span>. Enabling autosigning can be done securely:</span></p>

  <ol class="c10 lst-kix_xgh00yqd276z-0 start" start="1">
    <li class="c23 c4"><span>Ensure that the master port (8140 by default) is not
    accessible on the master's public IP address.<br />
    Default: Initial configuration of the</span> <span class=
    "c11">default</span><span>&nbsp;</span><span class="c3"><a class="c5" target="_blank" target="_blank" href=
    "/compute/docs/networking#networks">Compute Engine
    network</a></span><span>&nbsp;opens only the SSH port publicly.<br /></span></li>

    <li class="c23 c4"><span>Ensure that the master port is accessible on the master's
    private IP address.<br />
    Default: Initial configuration of the</span> <span class=
    "c11">default</span><span>&nbsp;</span><span>Compute Engine
    network</span><span>&nbsp;opens all TCP ports internally.<br /></span></li>

    <li class="c23 c4"><span>Specify</span> <span class=
    "c11">*.c.&lt;project&gt;.&lt;domain&gt;.internal</span><sup class="c11"><a href=
    "#ftnt3" name="ftnt_ref3" >[3]</a></sup><span>&nbsp;in the
    master's</span> <span class="c11">autosign.conf</span><span>&nbsp;file.<br />
    This limits autosigning to requests from instances on your project's internal
    network.</span></li>
  </ol>

  <p class="c4"><span>Enabling autosigning will allow you to get instances up and
  provisioned with their software catalog more quickly.</span></p>

  <p class="c4"><span>Be aware that</span> <span>when an agent instance is restarted, a
  new SSL certificate is generated and sent to the master, if one cannot be found. This
  can result in an authentication failure, as the master will already have accepted a
  different SSL certificate from an instance of the same name.</span></p>

  <p class="c4"><span>To handle this, on instance restart, make sure that either the
  Puppet</span> <span>SSL certificate</span> <span>is maintained on</span>
  <span>durable</span><span>&nbsp;storage available to the instance,</span> <span class=
  "c0">or</span><span>&nbsp;ensure that references to the original certificate are
  removed from the master. The former can most easily be achieved by booting from the
  instance's original persistent disk,</span> <span>the latter by executing</span>
  <span class="c11">puppet cert clean &lt;agent node&gt;</span><span>.</span></p><a href=
  "#" name="id.2t1c7r5ht97t" ></a>

  <h3 class="c4"><a name="h.piy6rj9zuv8g" ></a><span>Appendix C:
  Getting started with Chef on Compute Engine</span></h3>

  <p class="c31 c21 c4"><span class="c0 c36">Master/Agent</span></p>

  <p class="c25 c21 c4"></p>

  <h5 class="c31 c21 c4"><a name="h.57u9qd522i7x" id=
  "h.57u9qd522i7x"></a><span>Overview</span></h5>

  <p class="c31 c21 c4"><span><br />
  You will set up four Compute Engine instances:</span></p>

  <ul class="c10 lst-kix_13gido206bi1-0 start">
    <li class="c6 c4"><span class="c51">A chef server (</span><span class=
    "c51 c11">chef-server</span><span class="c51">), which will be used to store the
    cookbooks.</span></li>

    <li class="c6 c4"><span class="c51">A chef workstation (</span><span class=
    "c11 c51">chef-workstation</span><span class="c51">), which will be used to execute
    commands.</span></li>

    <li class="c6 c4"><span class="c51">Two chef client nodes, which will run the
    application code.</span></li>
  </ul>

  <p class="c4"><span>These instructions assume that you have</span> <span class=
  "c3"><a class="c5" target="_blank" target="_blank" href=
  "/compute/docs/gcutil">gcutil</a></span><span>&nbsp;installed.
  Execute</span></p>

  <ul class="c10 lst-kix_mjfwycy3u9jg-0 start">
    <li class="c23 c4"><span class="c11 c48 c19">green</span><span>&nbsp;instructions on
    your local workstation,</span></li>

    <li class="c23 c4"><span class="c11 c19 c81">blue</span><span>&nbsp;instructions on
    the Chef server, and</span></li>

    <li class="c23 c4"><span class="c16 c11">red</span><span class=
    "c11">&nbsp;</span><span>instructions on the Chef workstation.</span></li>
  </ul>

  <h5 class="c31 c21 c4"><a name="h.4ysr0cvzp519" ></a><span><br />
  Project</span></h5>

  <p class=" c4"><span>Run the following commands from your local</span>
  <span>workstation</span><span>.</span></p>

  <ol class="c10 lst-kix_lzer272i4ene-0 start" start="1">
    <li class="c6 c4"><span>Use the</span> <span class="c3"><a class="c5" target="_blank" target="_blank" href=
    "https://console.developers.google.com">Google Developers Console</a></span><span>&nbsp;or
    the</span> <span class="c11">gcloud</span><span>&nbsp;command to create a new
    project.</span></li>
  </ol>

  <p class="c31 c33 c21 c4"><span class="c11 c48 c19">gcloud config set project
  &lt;new-project-id&gt;</span></p>

  <ol class="c10 lst-kix_pvhrjk3vm7tw-0 start" start="2">
    <li class="c6 c4"><span>Add a</span> <span class="c3"><a class="c5" target="_blank" target="_blank" href=
    "/compute/docs/networking#addingafirewall">firewall
    rule</a></span><span>&nbsp;that will allow relevant traffic to your nodes. You can do
    this from the developers console (under Networks) or from the command line
    with</span> <span class="c11">gcutil</span><span>:</span></li>
  </ol>

  <p class="c31 c33 c21 c4"><span class="c11 c48 c19">gcutil addfirewall http-firewall
  --allowed=tcp:80<br />
  gcutil addfirewall https-firewall --allowed=tcp:443</span></p>

  <p class="c31 c21 c4"><span>&nbsp;</span><span><br />
  Ideally, restrict the firewalls to specific VMs</span> <span>by assigning tags to the
  VMs and using these tags in the firewalls.</span></p>

  <h5 class="c21 c4 c31"><a name="h.jyuik06xxrp7" ></a><span><br />
  Chef Server</span></h5>

  <ol class="c10 lst-kix_rhch4hyrj9j-0 start" start="1">
    <li class="c6 c4"><span>Create a</span> <span>Google Compute
    Engine</span><span>&nbsp;instance and name it</span> <span class=
    "c11">chef-server</span><span>.</span></li>
  </ol><a href="#" name="fb9fb93011ad78ca1e36c4c1e56fdf04d009bd67" id=
  "fb9fb93011ad78ca1e36c4c1e56fdf04d009bd67"></a><a href="#" name="9"></a>

  <ol class="c10 lst-kix_j1fkyf9wd699-0 start" start="2">
    <li class="c6 c4"><span>SSH to</span> <span class=
    "c11">chef-server</span><span>&nbsp;and run the following commands to set it up as a
    Chef Server:</span></li>
  </ol>

  <p class="c17 c4"><span class="c11 c19 c26">wget
  https://opscode-omnibus-packages.s3.amazonaws.com/el/6/x86_64/chef-server-11.0.8-1.el6.x86_64.rpm</span><br/>

  <span class="c26 c11 c19"><br />
  sudo apt-get update &amp;&amp; sudo apt-get update -y</span><br/>

  <span class="c26 c11 c19">sudo apt-get install alien</span><br/>

  <span class="c26 c11 c19">sudo alien --scripts -i
  chef-server-11.0.8-1.el6.x86_64.rpm</span><br/>
  <br />
  <span class="c26 c11 c19">
  sudo chef-server-ctl reconfigure &amp;&amp; sleep 30 &amp;&amp; sudo chef-server-ctl
  test</span></p>

  <h5 class="c4">Chef Workstation</h5>

  <ol class="c10 lst-kix_3dd451twg5yb-0 start" start="1">
    <li class="c6 c4"><span>Create a Compute Engine instance and name it</span>
    <span class="c11">chef-workstation</span><span>.</span></li>
  </ol><a href="#" name="fb9fb93011ad78ca1e36c4c1e56fdf04d009bd67" id=
  "fb9fb93011ad78ca1e36c4c1e56fdf04d009bd67"></a><a href="#" name="10"></a>

  <ol class="c10 lst-kix_7engtln0u4x-0 start" start="2">
    <li class="c6 c4"><span>SSH to</span> <span class=
    "c11">chef-workstation</span><span>&nbsp;and run the following commands to set it up
    as a Chef workstation.</span></li>
  </ol>

  <p class="c31 c33 c21 c4"><span class="c16 c11">sudo apt-get update &amp;&amp; sudo
  apt-get upgrade -y<br />
  curl -L https://www.opscode.com/chef/install.sh | sudo bash</span></p>

  <ol class="c10 lst-kix_5dmmhpqgo36g-0 start" start="3">
    <li class="c6 c4"><span>Make sure the</span> <span class=
    "c11">$USER</span><span>&nbsp;environment variable is set on your VM.</span></li>
  </ol>

  <p class="c17 c4"><span class="c16 c11">echo $USER # check if already set</span><br/>

  <span class="c16 c11">export USER=[your user name] # if not already
  set</span></p>

  <ol class="c10 lst-kix_5dmmhpqgo36g-0" start="4">
    <li class="c6 c4"><span>Copy the</span> <span class=
    "c11">.pem</span><span>&nbsp;files from</span> <span class=
    "c11">chef-server</span><span>&nbsp;to</span> <span class=
    "c11">chef-workstation</span><span>. You must make those files accessible on</span>
    <span class="c11">chef-server</span><span>&nbsp;so that they can be
    copied.</span></li>
  </ol>

  <p class="c31 c33 c21 c4"><span>On your local workstation, run:</span></p>

  <p class="c17 c4"><span class="c11 c48 c19">eval `ssh-agent`<br />
  ssh-add ~/.ssh/google_compute_engine</span></p>

  <p class="c37 c4"><span>SSH to</span> <span class=
  "c11">chef-server</span><span>&nbsp;and run:</span><span><br /></span></p>

  <p class="c17 c4"><span class="c26 c11 c19">sudo chmod 644
  /etc/chef-server/admin.pem<br />
  scp /etc/chef-server/admin.pem $USER@chef-workstation:~<br />
  sudo chmod 600 /etc/chef-server/admin.pem<br />
  sudo chmod 644 /etc/chef-server/chef-validator.pem<br />
  scp /etc/chef-server/chef-validator.pem $USER@chef-workstation:~<br />
  sudo chmod 600 /etc/chef-server/chef-validator.pem</span></p>

  <ol class="c10 lst-kix_mz7x38hlrume-0 start" start="5">
    <li class="c6 c4"><span>Back on &nbsp;</span><span class=
    "c11">chef-workstation</span><span>, put the</span> <span class=
    "c11">.pem</span><span>&nbsp;files</span> <span>into the right
    place</span><span>.</span></li>
  </ol>

  <p class="c31 c33 c21 c4"><span class="c16 c11">sudo mkdir /etc/chef-server<br />
  sudo mv admin.pem /etc/chef-server<br />
  sudo chmod 600 /etc/chef-server/admin.pem<br />
  sudo mv chef-validator.pem /etc/chef-server<br />
  sudo chmod 600 /etc/chef-server/chef-validator.pem<br />
  sudo apt-get install git<br />
  git clone git://github.com/opscode/chef-repo.git</span></p>

  <ol class="c10 lst-kix_scrpmw8e1s6u-0 start" start="6">
    <li class="c4 c6"><span>C</span><span>onfigure Knife.<br />
    When you execute the</span> <span class="c11">knife</span><span>&nbsp;command below,
    it will ask you a number of questions.</span></li>
  </ol>

  <ol class="c10 lst-kix_scrpmw8e1s6u-1 start" type="a">
    <li class="c31 c21 c4 c32"><span>For the</span> <span>server URL in the command, use
    the external IP address of your</span> <span class=
    "c11">chef-server</span><span>&nbsp;instance</span><span>, which you can find in
    the</span> <span class="c3"><a class="c5" target="_blank" href=
    "http://console.developers.google.com">Developers Console</a></span><span>. &nbsp;The full
    server URL will be of the form https://[server's external IP
    address]:443.</span></li>

    <li class="c32 c31 c21 c4"><span>Set the</span> <span class=
    "c11">cookbook_path</span><span>&nbsp;to</span> <span class=
    "c11">~/chef-repo</span><span>.</span></li>

    <li class="c32 c31 c21 c4"><span>Enter a password of at least 6 characters, or else
    the</span> <span class="c11">knife configure</span><span>&nbsp;command will exit with
    an error.</span></li>
  </ol>

  <p class="c31 c33 c21 c4"><span>On</span> <span class=
  "c11">chef-workstation</span><span>, run:<br /></span></p>

  <p class="c31 c33 c21 c4"><span class="c16 c11">knife configure -i &nbsp;# server:
  https://[server's external IP address]:443, &nbsp;cookbook_path =
  ~/chef-repo</span></p>

  <ol class="c10 lst-kix_6oq329on6qvz-0 start" start="7">
    <li class="c6 c4"><span>Verify that Knife is
    now</span><span>&nbsp;</span><span>working on</span> <span class=
    "c11">chef-workstation</span><span>.</span></li>
  </ol>

  <p class="c31 c33 c21 c4"><span class="c16 c11">knife client list<br />
  knife user list</span></p>

  <ol class="c10 lst-kix_5bfwaem9hbb3-0 start" start="8">
    <li class="c6 c4"><span>Install</span> <span class=
    "c11">knife-google</span><span>&nbsp;on</span> <span class=
    "c11">chef-workstation</span><span>.</span><span><br /></span></li>
  </ol>

  <p class="c31 c33 c21 c4"><span class="c16 c11">sudo /opt/chef/embedded/bin/gem install
  knife-google</span></p>

  <ol class="c10 lst-kix_p04ffttkx4u5-0 start" start="9">
    <li class="c6 c4"><span>Register your App from the</span> <span class="c3"><a class=
    "c5" target="_blank" href="https://console.developers.google.com">Developers
    Console</a></span><span>:</span></li>
  </ol>

  <ol class="c10 lst-kix_p04ffttkx4u5-1 start" type="a">
    <li class="c32 c31 c21 c4"><span>Under APIs &amp; auth,</span> <span>select
    Registered apps.</span></li>

    <li class="c32 c31 c21 c4"><span>Click on Register app and select Native.</span></li>

    <li class="c32 c31 c21 c4"><span>Y</span><span>ou will have a Client ID and a Client
    Secret, which you will use during the setup step
    below.</span><span><br /></span></li>
  </ol>

  <ol class="c10 lst-kix_p04ffttkx4u5-0" start="10">
    <li class="c6 c4"><span>Run the following commands on</span> <span class=
    "c11">chef-workstation</span><span>.</span><span><br /></span></li>
  </ol>

  <p class="c17 c4"><span class="c11 c16">knife google setup # use Project ID, Client ID,
  and Client Secret from above<br />
  knife google server list -Z us-central1-a<br />
  gcutil ssh `hostname -s`<br /></span></p>

  <p class="c17 c4"><span class="c16 c11">knife google server create
  google-compute-engine-1 \<br />
  &nbsp;-m n1-standard-1 -I [image of your choosing] \<br />
  &nbsp;-Z [zone of your choosing] -x $USER -i
  ~/.ssh/google_compute_engine<br /></span></p>

  <p class="c17 c4"><span class="c16 c11">knife google server create
  google-compute-engine-2 \<br />
  &nbsp;-m n1-standard-1 -I [image of your choosing] \<br />
  &nbsp;-Z [zone of your choosing] -x $USER -i ~/.ssh/google_compute_engine</span></p>

  <h5 class="c31 c21 c4"><a name="h.5ja2uo9gm33q" ></a><span><br />
  Setting up the cookbook</span></h5>

  <p class="c21 c4 c25"></p>

  <ol class="c10 lst-kix_8uuzx07ap2o3-0 start" start="1">
    <li class="c6 c4"><span>The easiest way to get started is by using a
    pre-existing</span> <span class="c3"><a class="c5" target="_blank" href=
    "https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fopscode-cookbooks&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEwxgScspoP9AeRp6MAq9HgYv02Lw">
    open source</a></span><span class="c3"><a class="c5" target="_blank" href=
    "https://github.com/opscode-cookbooks">&nbsp;cookbook</a></span><span>.<br />
    Run the following commands on</span> <span class=
    "c11">chef-workstation</span><span>.</span></li>
  </ol>

  <p class="c31 c33 c21 c4">
  <span class="c16 c11">knife cookbook site install apt<br/>
  knife cookbook site install apache2<br/>
  knife cookbook upload apt apache2</span></p>

  <ol class="c10 lst-kix_lq34sltwmv9a-0 start" start="2">
    <li class="c6 c4"><span>To run the gce cookbook, you must upload the cookbook to the
    server and add the cookbook to your nodes' run lists. To do this, run the following
    commands from</span> <span class="c11">chef-workstation</span><span>.</span></li>
  </ol>

  <p class="c31 c33 c21 c4"><span class="c16 c11">knife cookbook upload apt apache2 -o
  ~/chef-repo/cookbooks/<br />
  knife node run_list add google-compute-engine-1 'apt' 'apache2'<br />
  knife node run_list add google-compute-engine-2 'apt' 'apache2'</span></p>

  <ol class="c10 lst-kix_5tw2vnmttw0e-0 start" start="3">
    <li class="c6 c4"><span>You can manually execute the recipe by running</span>
    <span class="c11">chef-client</span><span>&nbsp;from each of the nodes. This command
    will contact the server, get the latest recipes, and execute them. To do this,</span>
    <span class="c11">ssh</span><span>&nbsp;into each of the nodes and execute the
    following command.<br /></span></li>
  </ol>

  <p class="c31 c33 c21 c4"><span class="c11 c19">sudo chef-client</span></p>

  <h3 class="c72 c4"><a name="h.8evvglmlboe8" ></a><span>Appendix D:
  Getting started with Salt on Compute Engine</span></h3>

  <h4 class="c4"><a name="h.ufw4ayp6nhhs" ></a><span>Set up the
  Salt Master</span></h4>

  <p class="c4"><span>This</span> section assumes you will be running the Salt
  Master within Compute Engine. The v2014.1.0 (Hydrogen) release of Salt and
  v0.14.1 of <span class="c3"><a class="c5" target="_blank"
  href="http://libcloud.apache.org">libcloud</a></span> are required.</p>

  <h5 class="c4"><a name="h.ufllbdsc2zd" ></a><span>Set up Compute
  Engine credentials</span></h5>

  <ol class="c10 lst-kix_b5di6ccllmke-0 start" start="1">
    <li class="c23 c4"><span>Make sure you have a</span> <span>Client ID Service
    Account</span><span>. You will need the Service Account's generated email address
    (e.g. 'long-hash-address@developer.gserviceaccount.com') and the private key file.
    You can use the</span> <span class="c3"><a class="c5" target="_blank" href=
    "https://console.developers.google.com">Google Cloud Console</a></span><span>&nbsp;to
    create the</span> <span class="c3"><a class="c5" target="_blank" href=
    "https://developers.google.com/console/help/new/#serviceaccounts">Service
    Account</a></span><span>.<br /></span></li>

    <li class="c23 c4"><span>Create a copy of the private key in a format allowed by the
    Python cryptographic library. You can use the</span> <span class=
    "c11">openssl</span><span>&nbsp;command (</span><span class="c69"><a class="c5" target="_blank" href=
    "http://www.openssl.org/">http://www.openssl.org/</a></span><span>)</span><span>&nbsp;to
    convert the format. (Note that when prompted, the default password is</span>
    <span class="c19">notasecret.</span><span>)<br />
    <br /></span><span class="c11">openssl pkcs12 -in long-hash.p12 -nodes -nocerts
    \<br />
    &nbsp; &nbsp;| openssl rsa -out /path/to/your/pkey.pem</span></li>
  </ol>

  <h5 class="c4"><a name="h.f0eo4rp3xhsp" ></a><span>Set up the Salt Master and
  configure Salt-Cloud</span></h5>

  <p class="c4"><span>S</span><span>alt is normally</span><span>&nbsp;run as the</span>
  <span class="c11">root</span><span>&nbsp;super-user. Unless otherwise noted, all
  commands below assume you have</span> <span>already</span><span>&nbsp;become the</span>
  <span class="c11">root</span><span>&nbsp;user.</span></p>

  <ol class="c10 lst-kix_nbyxmtnfbfo-0 start" start="1">
    <li class="c23 c4"><span>Create a Compute Engine instance for the Salt Master.
    This can be done in the <span class="c3"><a class="c5" target="_blank"
    href="https://console.developers.google.com">Developers Console</a></span> or
    with <span class="c11">gcutil addinstance</span>. When creating the new
    instance, it is recommended that you use <span class="c11">salt</span> as the
    instance's name. This is the expected default and will seamlessly work with
    Compute Engine's internal DNS resolution.</span><span><br /></span></li>

    <li class="c23 c4"><span>Connect to the Salt Master with <span class="c11">gcutil
    ssh</span>.</span><span><br /></span></li>

    <li class="c23 c4"><span>Install Salt with the bootstrap script.
    <br /></span><span class="c11">curl -o bootstrap.sh -L http://bootstrap.saltstack.org<br />
    sh bootstrap.sh -M -N git v2014.1.0</span><span><br /></span></li>

    <li class="c23 c21 c4"><span>Create the main "cloud" configuration file for Salt.
    &nbsp;You need:</span></li>
  </ol>

  <ol class="c10 lst-kix_nbyxmtnfbfo-1 start"  type="a">
    <li class="c32 c21 c4"><span>Project ID</span></li>

    <li class="c32 c21 c4"><span>Service Account email address (ends with
    @developer.gserviceaccount.com)</span></li>

    <li class="c32 c21 c4"><span>location of your converted private key
    <br /></span><span class="c11">cat &gt; /etc/salt/cloud &lt;&lt;EOF<br />
    providers:<br />
    &nbsp;gce-config:<br />
    &nbsp; &nbsp;project: 'YOUR_PROJECT_ID'<br />
    &nbsp; &nbsp;service_account_email_address: '</span><span class=
    "c11">...@developer.gserviceaccount.com'</span><span class="c11"><br />
    &nbsp; &nbsp;service_account_private_key: '/path/to/your/pkey.pem'<br />
    &nbsp; &nbsp;provider: gce<br />
    EOF<br /></span></li>
  </ol>

  <ol class="c10 lst-kix_nbyxmtnfbfo-0" start="5">
    <li class="c23 c21 c4"><span>Create the cloud profile config file.<br />
    This example specifies profiles for both a master and a minion.<br />
    <br /></span><span class="c11">cat &gt; /etc/salt/cloud.profiles &lt;&lt;EOF<br />
    salt_minion:<br />
    &nbsp;minion:<br />
    &nbsp; &nbsp;master: salt<br />
    &nbsp;image: debian-7-wheezy-v20131120<br />
    &nbsp;size: n1-standard-1<br />
    &nbsp;location: us-central2-a<br />
    &nbsp;make_master: False<br />
    &nbsp;deploy: True<br />
    &nbsp;tags: '["minion", "salt"]'<br />
    &nbsp;provider: gce-config<br />
    EOF</span><span><br /></span></li><br>

    <li class="c23 c21 c4"><span>Make sure your local</span> <span class=
    "c11">root</span><span>&nbsp;user has a Compute Engine ssh key defined with the
    metadata server.
    <br /></span><span class="c11">gcutil ssh --permit_root_ssh $(</span><span class=
    "c11">hostname -s</span><span class="c11">)<br /></span></li>
  </ol>

  <ol class="c10 lst-kix_nbyxmtnfbfo-1" type="a">
    <li class="c32 c21 c4"><span>When prompted, create a passphrase for the new
    key.</span></li>

    <li class="c32 c21 c4"><span>When the command completes, it will have logged you in
    to the instance again.</span></li>

    <li class="c32 c21 c4"><span>Exit the</span> <span class="c11">gcutil
    ssh</span><span>&nbsp;session</span><span>&nbsp;to get back to your original login
    session.<br /></span></li>
  </ol>

  <ol class="c10 lst-kix_nbyxmtnfbfo-0" start="7">
    <li class="c23 c21 c4"><span>Create and provision three minions with the</span>
    <span class="c11">salt_minion</span><span>&nbsp;profile. The command will
    create the Compute Engine instances, generate certificates, and execute a
    deploy script on the new instances to provision them as Salt minions.
    <br /></span><span class="c11">salt-cloud -p salt_minion
    minion{1..3}</span><span><br /></span></li>

    <li class="c23 c21 c4"><span>On the master, verify that the minions can be reached
    with a simple ping test. You should see a</span> <span class=
    "c11">True</span><span>&nbsp;response for each minion.
    <br /></span><span class="c11">salt 'minion*'
    test.ping</span><span><br /></span></li>
  </ol>

  <h5 class="c21 c4"><a name="h.9js9x1p5trjl" ></a><span>Managing
  minions from the master</span></h5>

  <p class="c4"><span>Now that the master and minions have been created, all minion
  management will be performed from the master. You will create the configuration files
  to install an Apache web server on each minion along with a custom</span> <span class=
  "c11">index.html</span><span>&nbsp;page.</span></p>

  <p class="c50 c21 c4"></p>

  <ol class="c10 lst-kix_s90g81djwhtb-0 start" start="1">
    <li class="c23 c21 c4"><span>Log into the master as</span> <span class=
    "c11">root.</span></li>

    <li class="c23 c21 c4"><span>Create the directory tree for the configuration
    files.
    <br /></span><span class="c11">mkdir -p /srv/salt/webserver<br /></span></li>

    <li class="c23 c21 c4"><span>Create a basic</span> <span class=
    "c11">top.sls</span><span>&nbsp;state file to match your webserver configuration to
    your minions&rsquo; hosts.
    <br /></span><span class="c11">cat &gt; /srv/salt/top.sls &lt;&lt;EOF<br />
    base:<br />
    &nbsp;'minion*':<br />
    &nbsp; &nbsp;- webserver<br />
    EOF</span><span><br /></span></li>

    <li class="c23 c21 c4"><span>Create the</span> <span class=
    "c11">webserver</span><span>&nbsp;state file, which is used to ensure the</span>
    <span class="c11">apache2</span><span>&nbsp;Debian package is installed, the service
    is running, and the custom</span> <span class="c11">index.html</span><span>&nbsp;is
    deployed.
    <br /></span><span class="c11">cat &gt; /srv/salt/webserver/init.sls
    &lt;&lt;EOF<br />
    apache2:<br />
    &nbsp;pkg:<br />
    &nbsp; &nbsp;- installed<br />
    &nbsp;service:<br />
    &nbsp; &nbsp;- running<br />
    <br />
    /var/www/:<br />
    &nbsp;file.managed:<br />
    &nbsp; &nbsp;- source: salt://webserver/<br />
    &nbsp; &nbsp;- user: root<br />
    &nbsp; &nbsp;- group: root<br />
    &nbsp; &nbsp;- mode: 644<br />
    &nbsp; &nbsp;- template: jinja<br />
    &nbsp; &nbsp;- require:<br />
    &nbsp; &nbsp; &nbsp;- pkg: apache2</span></li>

    <li class="c23 c21 c4"><span>Write out the custom</span> <span class=
    "c11">index.html</span><span>&nbsp;file as a Jinja template</span> <span>that will
    utilize the minion's local</span> <span class="c3"><a class="c5" target="_blank" href=
    "http://docs.saltstack.com/topics/targeting/grains.html">grains</a></span><span>.
    <br /></span><span class="c11">cat &gt; /srv/salt/webserver/
    &lt;&lt;EOF<br />
    &lt;html&gt;<br />
    &lt;title&gt;Welcome to '&#123;&#123; grains.id &#125;&#125;'&lt;/title&gt;<br />
    &lt;body&gt;<br />
    Here are some facts auto-generated from local grains.<br />
    &lt;pre&gt;<br />
    &nbsp; &nbsp;hostname: &#123;&#123; grains.id &#125;&#125;<br />
    &nbsp; &nbsp;eth0 ip: &#123;&#123; grains.fqdn_ip4[0] &#125;&#125;<br />
    &nbsp; &nbsp;my master: &#123;&#123; grains.master &#125;&#125;<br />
    &nbsp; &nbsp;manufacturer: &#123;&#123; grains.manufacturer &#125;&#125;<br />
    &lt;/pre&gt;<br />
    &lt;/body&gt;<br />
    &lt;/html&gt;</span><span><br /></span></li>
    <li class="c23 c21 c4"><span>Apply the configuration across all minions.
    <br /></span><span class="c11">salt 'minion</span><span class=
    "c11">*</span><span class="c11">' state.highstate</span></li>
  </ol>

  <h3 class="c72 c4"><a name="h.93f130z3buv0" ></a><span>Appendix E:
  Getting started with Ansible on Compute Engine</span></h3>

  <p class="c4"><span>Ansible depends on</span> <span class="c3"><a class="c5" target="_blank" href=
  "http://libcloud.apache.org">libcloud</a></span><span>&nbsp;version 0.14.1 or
  greater.</span></p>

  <h4 class="c4"><a name="h.bqzzrg2uo9q5" ></a><span>Set up Compute
  Engine credentials</span></h4>

  <ol class="c10 lst-kix_gh6of2b6wq85-0 start" start="1">
    <li class="c23 c4"><span>Make sure you have a</span> <span>Client ID Service
    Account</span><span>. You will need the Service Account's generated email address
    (e.g. '</span><span>long-hash-address@developer.gserviceaccount.com'</span><span>)
    and the private key file. You can use the</span> <span class="c3"><a class="c5" target="_blank" href=
    "https://console.developers.google.com">Google Cloud Console</a></span><span>&nbsp;to
    create the</span> <span class="c3"><a class="c5" target="_blank" href=
    "https://developers.google.com/console/help/new/#serviceaccounts">Service
    Account</a></span><span>.<br /></span></li>

    <li class="c23 c4"><span>A copy of the private key must be created in a format
    allowed by the Python cryptographic library. You can use the</span> <span class=
    "c11">openssl</span><span>&nbsp;command &nbsp;(</span><span class="c69"><a class="c5"
    target="_blank" href="http://www.openssl.org/">http://www.openssl.org/</a></span><span>) &nbsp;to
    convert the format (note that when prompted, the default password is</span>
    <span class="c19">notasecret</span><span>).
    <br /></span><span class="c11">openssl pkcs12 -in long-hash.p12 -nodes -nocerts
    \<br />
    &nbsp; &nbsp;| openssl rsa -out /path/to/your/pkey.pem</span><span><br /></span></li>

  </ol>

  <h4 class="c4"><a name="h.uts8ii9k5yoy" ></a><span>Set up
  Ansible</span></h4>

  <ol class="c10 lst-kix_afklgldnt9jc-0 start" start="1">
    <li class="c23 c4"><span>The steps below are based on the instructions for</span>
    <span class="c3"><a class="c5" target="_blank" href=
    "http://www.ansibleworks.com/docs/intro_installation.html#running-from-source">Running
    from Source</a></span><span>.
    <br /></span><span class="c11">git clone git://github.com/ansible/ansible.git<br />
    cd ./ansible<br />
    source ./hacking/env-setup<br /></span></li>

    <li class="c23 c4"><span>Create a static inventory file and set your
    environment.
    <br /></span><span class="c11">cat &gt; ~/inv.ini &lt;&lt; EOF<br />
    [local]<br />
    localhost<br />
    <br />
    [gce_instances]<br />
    www1<br />
    www2<br />
    EOF<br />
    export ANSIBLE_HOSTS=~/inv.ini</span><span><br /></span></li>

    <li class="c23 c4"><span>Create a sample playbook file named</span> <span class=
    "c11">gce.yml</span><span>. The file specifies</span> <span>that
    two</span><span>&nbsp;Debian Compute Engine instances are created, and the Apache web
    server is installed on each instance along with a custom</span> <span class=
    "c11">index.html</span><span>&nbsp;page. The playbook also sets a firewall rule to
    open up HTTP traffic. Note that the Compute Engine instance names and the
    "</span><span>play</span><span>" (a grouping of tasks within the playbook) for
    installing software on them (</span><span class="c19">bolded</span><span>&nbsp;below)
    match the</span> <span class="c11">[gce_instances]</span><span>&nbsp;inventory
    section in the static inventory file created in the previous step.<br /></span></li>
  </ol><a href="#" name="fbec9778db09b02f0afb9e56ab36be917fad44d3" id=
  "fbec9778db09b02f0afb9e56ab36be917fad44d3"></a><a href="#" name="11"></a>

  <table cellpadding="0" cellspacing="0" class="c33 c76">
    <tbody>
      <tr>
        <td class="c35">
          <p class="c12 c4"><span class="c11">- name: Create Compute Engine
          instances<br />
          &nbsp;&nbsp;hosts: local<br />
          &nbsp;&nbsp;gather_facts: no<br />
          &nbsp;&nbsp;vars:<br />
          &nbsp;&nbsp; &nbsp;names:</span> <span class="c11 c19">www1,www2</span><span class=
          "c11"><br />
          &nbsp;&nbsp; &nbsp;machine_type: n1-standard-1<br />
          &nbsp;&nbsp; &nbsp;image: debian-7<br />
          &nbsp;&nbsp; &nbsp;zone: us-central1-a<br />
          &nbsp;&nbsp; &nbsp;pid: YOUR_PROJECT_ID<br />
          &nbsp;&nbsp; &nbsp;email: YOUR_SERVICE_ACCOUNT_EMAIL<br />
          &nbsp;&nbsp; &nbsp;pem: /path/to/your/pkey.pem<br />
          &nbsp;&nbsp;tasks:<br />
          &nbsp;&nbsp; &nbsp;- name: Launch instances<br />
          &nbsp;&nbsp; &nbsp; &nbsp;local_action: gce instance_names="&#123;&#123; names &#125;&#125;"<br />
          &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;machine_type="&#123;&#123; machine_type &#125;&#125;"<br />
          &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;image="&#123;&#123; image &#125;&#125;" zone="&#123;&#123; zone &#125;&#125;"<br />
          &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;project_id="&#123;&#123; pid &#125;&#125;" pem_file="&#123;&#123; pem &#125;&#125;"<br />
          &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;service_account_email="&#123;&#123; email &#125;&#125;"<br />
          &nbsp;&nbsp; &nbsp; &nbsp;register: gce<br />
          &nbsp;&nbsp; &nbsp;- name: Wait for SSH to come up<br />
          &nbsp;&nbsp; &nbsp; &nbsp;local_action: wait_for host="&#123;&#123; item.public_ip &#125;&#125;" port=22 delay=10<br />
          &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;timeout=60 state=started<br />
          &nbsp;&nbsp; &nbsp; &nbsp;with_items: gce.instance_data<br />
          <br />
          - name: Install apache, set a custom index.html<br />
          &nbsp;&nbsp;hosts:</span> <span class="c11 c19">gce_instances</span><span class="c11"><br />
          &nbsp;&nbsp;sudo: yes<br />
          &nbsp;&nbsp;tasks:<br />
          &nbsp;&nbsp; &nbsp;- name: Install apache<br />
          &nbsp;&nbsp; &nbsp; &nbsp;apt: pkg=apache2 state=present<br />
          &nbsp;&nbsp; &nbsp;- name: Create custom index.html<br />
          &nbsp;&nbsp; &nbsp; &nbsp;copy: dest=/var/www/ content='Hi, I am &#123;&#123; ansible_hostname &#125;&#125;'<br />
          &nbsp;&nbsp; &nbsp;- name: set file stats on index.html<br />
          &nbsp;&nbsp; &nbsp; &nbsp;file: path=/var/www/ owner=root group=root mode=0644<br />
          &nbsp;&nbsp; &nbsp;- name: Start apache<br />
          &nbsp;&nbsp; &nbsp; &nbsp;service: name=apache2 state=started<br />
          <br />
          - name: Create a firewall rule to allow HTTP<br />
          &nbsp;&nbsp;hosts: localhost<br />
          &nbsp;&nbsp;gather_facts: no<br />
          &nbsp;&nbsp;vars:<br />
          &nbsp;&nbsp; &nbsp;pid: YOUR_PROJECT_ID<br />
          &nbsp;&nbsp; &nbsp;email: YOUR_SERVICE_ACCOUNT_EMAIL<br />
          &nbsp;&nbsp; &nbsp;pem: /path/to/your/pkey.pem<br />
          &nbsp;&nbsp;tasks:<br />
          &nbsp;&nbsp; &nbsp;- name: Allow HTTP<br />
          &nbsp;&nbsp; &nbsp; &nbsp;local_action: gce_net fwname=all-http name=default allowed=tcp:80<br />
          &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;project_id="&#123;&#123; pid &#125;&#125;" pem_file="&#123;&#123; pem &#125;&#125;"<br />
          &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;service_account_email="&#123;&#123; email &#125;&#125;"<br />
          </span></p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="c50 c4"></p>

  <ol class="c10 lst-kix_afklgldnt9jc-0" start="4">
    <li class="c23 c4"><span>For testing purposes, you may wish to disable SSH host key
    verification with an environment variable.
    <br /></span><span class="c11">export
    ANSIBLE_HOST_KEY_CHECKING=False</span><span><br /></span></li>

    <li class="c23 c4"><span>Now execute the Ansible playbook command to performed the
    plays specified in the</span> <span class=
    "c11">gce.yml</span><span>&nbsp;file. If you are using the Compute Engine default
    ssh keys, you can specify that with the <span class="c11">--private-key</span>
    argument,</span><span><br /></span><span
    class="c11">ansible-playbook --private-key=~/.ssh/google_compute_engine ~/gce.yml</span></li>
  </ol>

  <hr />

  <div>
    <p class="c18 c4"><a target="_blank" href="/developers/articles/google-compute-engine-management-puppet-chef-salt-ansible#ftnt_ref1" name="ftnt1" id=
    "ftnt1">[1]</a><span>&nbsp;Source:</span> <span class="c3"><a class="c5" target="_blank" href=
    "http://www.packer.io/">http://www.packer.io/</a></span></p>
  </div>

  <div>
    <p class="c18 c4"><a target="_blank" href="/developers/articles/google-compute-engine-management-puppet-chef-salt-ansible#ftnt_ref2" name="ftnt2" id=
    "ftnt2">[2]</a><span>&nbsp;Source:</span> <span class="c3"><a class="c5" target="_blank" href=
    "http://www.vagrantup.com/">http://www.vagrantup.com/</a></span></p>
  </div>

  <div>
    <p class="c4 c18"><a href="#ftnt_ref3" name="ftnt3" >[3]</a><span>&nbsp;If
    you are uncertain of your internal domain, execute</span> <span class="c11">hostname
    --domain</span><span>&nbsp;on the Puppet master instance.</span></p>
  </div>
</div>


    </div>
</div>
</div>
</div>


</body>
</html>
